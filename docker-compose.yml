services:
  python_server:
    build: ./llm_assignment
    container_name: python_server
    volumes:
      - ./llm_assignment:/app
    ports:
      - "${PYTHON_PORT}:${PYTHON_PORT}"
    command: ${PYTHON_COMMAND}
    env_file:
      - .env
    environment:
      - conversation_endpoint=http://node_server:${NODE_PORT}/api/conversations

  node_server:
    build: ./node_api_server
    container_name: node_server
    volumes:
      - ./node_api_server:/app
    ports:
      - "${NODE_PORT}:${NODE_PORT}"
    command: ${NODE_COMMAND}
    depends_on:
      - python_server
    env_file:
      - .env
    environment:
      - ai_endpoint=http://python_server:${PYTHON_PORT}/api/ai
  
  frontend:
    build: ./distributed-llm-frontend
    container_name: frontend
    ports:
      - "3000:3000"
    environment:
      - REACT_APP_API_URL=http://localhost:${NODE_PORT}/api/conversations
    depends_on:
      - node_server
    env_file:
      - .env
    volumes:
      - ./distributed-llm-frontend:/app/frontend
    command: ${REACT_COMMAND}
